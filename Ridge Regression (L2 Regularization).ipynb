{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression (linear regression with L2 regularisation)\n",
    "\n",
    "### Task I: Derivation of weight update steps of Stocastic Gradient Descent (SGD) and Batch Gradient Descent (BGD) for Linear Regression with L2 Regularization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(warn=-1) #to stop the warnings\n",
    "library(ggplot2) # for plotting functions.\n",
    "library(reshape2) # for melt and cast functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning values to variables used globally "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set initial values for learning rate, termination thershold and lambda \n",
    "epsilon = .001\n",
    "eta = .01\n",
    "lambda = 0.02\n",
    "max_epoch = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data\n",
    "read_data <- function(fname, sc) {\n",
    "   data <- read.csv(file=fname,head=TRUE,sep=\",\")\n",
    "   nr = dim(data)[1]\n",
    "   nc = dim(data)[2]\n",
    "   x = data[1:nr,1:(nc-1)]\n",
    "   y = data[1:nr,nc]\n",
    "   if (isTRUE(sc)) {\n",
    "      x = scale(x)\n",
    "      y = scale(y)\n",
    "   }\n",
    "   return (list(\"x\" = x, \"y\" = y))\n",
    "}\n",
    "\n",
    "dtrain = read_data(\"Task1C_train.csv\", TRUE)\n",
    "dtest = read_data(\"Task1C_test.csv\", TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary function to calculate labels based on the estimated coefficients\n",
    "predict_func <- function(Phi, w){\n",
    "    return(Phi%*%w) ## Calculate matrix product.\n",
    "} \n",
    "\n",
    "# auxiliary function to calculate the objective function for the training\n",
    "train_obj_func <- function (Phi, w, label, lambda){\n",
    "    # the L2 regulariser is included in the objective function for training \n",
    "    return(mean((predict_func(Phi, w) - label)^2) + .5 * lambda * w %*% w)\n",
    "}\n",
    "\n",
    "# auxiliary function to compute the error of the model\n",
    "get_errors <- function(train_data, test_data, W) {\n",
    "   n_weights = dim(W)[1]\n",
    "   errors = matrix(,nrow=n_weights, ncol=2)\n",
    "   for (tau in 1:n_weights) {\n",
    "      errors[tau,1] = train_obj_func(train_data$x, W[tau,],train_data$y, lambda) # tracks training error\n",
    "      errors[tau,2] = train_obj_func(test_data$x, W[tau,],test_data$y, lambda) # tracks testing error\n",
    "   }\n",
    "   return(errors)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task II: Implementation of SGD and BGD algorithms in R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating the SGD weight vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_update_weight <- function(W_prev, x, y_true, y_pred, lambda, eta) {\n",
    "   # L2 REG penalty term lambda * W_prev is added to grad\n",
    "   grad = - (y_true-y_pred) * x + (lambda * W_prev)\n",
    "   return(W_prev - eta * grad)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating the BGD weight vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgd_update_weight <- function(W_prev, x, y_true, y_pred, lambda, eta) {\n",
    "   # MODIFY THIS FUNCTION FOr L2 REG\n",
    "   grad = -colMeans(matrix((y_true-y_pred),nrow=dim(x)[1],ncol=dim(x)[2]) * x) + (lambda * W_prev)\n",
    "   return (W_prev - eta * grad)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation of Stocastic Gradient Descent (SGD) for Linear Regression with L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_train <- function(train_x, train_y, lambda, eta, epsilon, max_epoch) {\n",
    "\n",
    "   train_len = dim(train_x)[1]\n",
    "   tau_max = max_epoch * train_len # Maximum number of iterations\n",
    "\n",
    "   W <- matrix(,nrow=tau_max, ncol=ncol(train_x)) # empty matrix to store weight vector\n",
    "   W[1,] <- runif(ncol(train_x))\n",
    "  \n",
    "   tau = 1 # counter \n",
    "   obj_func_val <-matrix(,nrow=tau_max, ncol=1) \n",
    "   obj_func_val[tau,1] = train_obj_func(train_x, W[tau,],train_y, lambda)\n",
    "\n",
    "   while (tau <= tau_max){\n",
    "\n",
    "       # check termination criteria\n",
    "       if (obj_func_val[tau,1]<=epsilon) {break}\n",
    " \n",
    "       # shuffle data:\n",
    "       train_index <- sample(1:train_len, train_len, replace = FALSE)\n",
    "    \n",
    "       # loop over each datapoint\n",
    "       for (i in train_index) {\n",
    "           # increment the counter\n",
    "           tau <- tau + 1\n",
    "           if (tau > tau_max) {break}\n",
    "\n",
    "           # make the weight update\n",
    "           y_pred <- predict_func(train_x[i,], W[tau-1,])\n",
    "           W[tau,] <- sgd_update_weight(W[tau-1,], train_x[i,], train_y[i], y_pred, lambda, eta)\n",
    "\n",
    "           # keep track of the objective funtion\n",
    "           obj_func_val[tau,1] = train_obj_func(train_x, W[tau,],train_y, lambda)\n",
    "       }\n",
    "   }\n",
    "   # resulting values for the training objective function as well as the weights\n",
    "   return(list('vals'=obj_func_val,'W'=W))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation of Batch Gradient Descent (BGD) for Linear Regression with L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgd_train <- function(train_x, train_y, lambda, eta, epsilon, max_epoch) {\n",
    "\n",
    "   train_len = dim(train_x)[1]\n",
    "\n",
    "   W <- matrix(,nrow=(max_epoch+1), ncol=ncol(train_x))\n",
    "   W[1,] <- runif(ncol(train_x))\n",
    "\n",
    "   tau = 1 # counter \n",
    "   obj_func_val <-matrix(,nrow=(max_epoch+1), ncol=1)\n",
    "   obj_func_val[tau,1] = train_obj_func(train_x, W[tau,],train_y, lambda)\n",
    "\n",
    "   trainin_size = dim(train_x)[1]\n",
    "   for (tau in 1:max_epoch){\n",
    "\n",
    "       # check termination criteria\n",
    "       if (obj_func_val[tau,1]<=epsilon) {break}\n",
    "\n",
    "       # make prediction over the training set\n",
    "       y_pred = train_x %*% W[tau,]\n",
    "\n",
    "       # update the weight you may decide to chose linea search or not (we are not using line search here)\n",
    "       W[tau+1,] = bgd_update_weight(W[tau,], train_x, train_y, y_pred, lambda, eta)\n",
    "\n",
    "       # keep track of the objective funtion\n",
    "       obj_func_val[tau+1,1] = train_obj_func(train_x, W[tau+1,],train_y, lambda)\n",
    "   } \n",
    "   # resulting values for the training objective function as well as the weights\n",
    "   return(list('vals'=obj_func_val,'W'=W))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task III: Compare SGD and BGD implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run SGD and BGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_train_res = sgd_train(dtrain$x, dtrain$y, lambda, eta, epsilon, max_epoch) # Initialize and run SGD\n",
    "sgd_errors = get_errors(dtrain, dtest, sgd_train_res$W)\n",
    "\n",
    "bgd_train_res = bgd_train(dtrain$x, dtrain$y, lambda, eta, epsilon, max_epoch) # Initialize and run BGD\n",
    "bgd_errors = get_errors(dtrain, dtest, bgd_train_res$W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot of error rates for SGD and BGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAAAAAP9NTU1oaGh8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\nIUEAIUGA/wBHK7Ba+F3XoQAAAABJRU5ErkJggg==",
      "text/plain": [
       "Plot with title \"Error Rates Using SGD vs BGD\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(bgd_errors[,1], type=\"p\", col=\"blue\",ylim=c(0,1), xlim=c(0,18600), xlab=\"Number of Iterations\", ylab=\"Error\",main=\"Error Rates Using SGD vs BGD\")\n",
    "lines(sgd_errors[,1], type=\"l\", col=\"black\")\n",
    "legend(\"topright\", legend = c(\"SGD\", \"BGD\"), col = c(1, 4), pch = c(15, 15))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
